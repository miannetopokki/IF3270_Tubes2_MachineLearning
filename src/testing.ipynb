{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dae489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data_preprocessing import NusaXSentimentDataProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ab6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(x_train, y_train, x_val, y_val, x_test, y_test, data_processor):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the preprocessed data\n",
    "    \"\"\"\n",
    "    print(\"\\n===== Data Analysis =====\")\n",
    "    \n",
    "    print(\"\\n--- Data Shapes ---\")\n",
    "    print(f\"Training data: {x_train.shape}\")\n",
    "    print(f\"Training labels: {y_train.shape}\")\n",
    "    print(f\"Validation data: {x_val.shape}\")\n",
    "    print(f\"Validation labels: {y_val.shape}\")\n",
    "    print(f\"Test data: {x_test.shape}\")\n",
    "    print(f\"Test labels: {y_test.shape}\")\n",
    "    \n",
    "    print(\"\\n--- Label Mapping ---\")\n",
    "    print(\"Label mapping:\")\n",
    "    for label, idx in data_processor.label_mapping.items():\n",
    "        print(f\"  {label} -> {idx}\")\n",
    "    \n",
    "    print(\"\\n--- Label Distribution ---\")\n",
    "    train_label_dist = np.bincount(y_train.astype(int))\n",
    "    val_label_dist = np.bincount(y_val.astype(int))\n",
    "    test_label_dist = np.bincount(y_test.astype(int))\n",
    "    \n",
    "    idx_to_label = {v: k for k, v in data_processor.label_mapping.items()}\n",
    "    \n",
    "    for i in range(len(train_label_dist)):\n",
    "        label_name = idx_to_label.get(i, f\"Unknown-{i}\")\n",
    "        print(f\"Class {i} ({label_name}): Train={train_label_dist[i]} ({train_label_dist[i]/len(y_train):.2%}), \"\n",
    "              f\"Val={val_label_dist[i] if i < len(val_label_dist) else 0} \"\n",
    "              f\"({val_label_dist[i]/len(y_val):.2%} if i < len(val_label_dist) else 0.0), \"\n",
    "              f\"Test={test_label_dist[i] if i < len(test_label_dist) else 0} \"\n",
    "              f\"({test_label_dist[i]/len(y_test):.2%} if i < len(test_label_dist) else 0.0)\")\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"\\n--- Vocabulary Information ---\")\n",
    "    vocab_size = data_processor.get_vocabulary_size()\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    \n",
    "    vocab = data_processor.vectorize_layer.get_vocabulary()\n",
    "    print(\"Top 20 vocabulary items:\")\n",
    "    for i, word in enumerate(vocab[:20]):\n",
    "        print(f\"  {i}: {word}\")\n",
    "    \n",
    "    print(\"\\n--- Sample Data ---\")\n",
    "    num_samples = min(5, len(x_train))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        label_idx = int(y_train[i])\n",
    "        label_name = idx_to_label.get(label_idx, f\"Unknown-{label_idx}\")\n",
    "        print(f\"Label: {label_idx} ({label_name})\")\n",
    "        tokens = x_train[i]\n",
    "        non_zero_tokens = tokens[tokens > 0]\n",
    "        print(f\"Sequence length: {len(non_zero_tokens)}\")\n",
    "        print(\"Tokens:\", non_zero_tokens[:10], \"...\" if len(non_zero_tokens) > 10 else \"\")\n",
    "        if len(vocab) > 1:\n",
    "            print(\"First few tokens decoded:\")\n",
    "            for token_idx in non_zero_tokens[:10]:\n",
    "                if token_idx < len(vocab):\n",
    "                    print(f\"  {token_idx}: {vocab[token_idx]}\")\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f74c329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Unique labels found: {'negative', 'positive', 'neutral'}\n",
      "Train data: 500 samples\n",
      "Validation data: 100 samples\n",
      "Test data: 400 samples\n",
      "\n",
      "===== Data Analysis =====\n",
      "\n",
      "--- Data Shapes ---\n",
      "Training data: (500, 100)\n",
      "Training labels: (500,)\n",
      "Validation data: (100, 100)\n",
      "Validation labels: (100,)\n",
      "Test data: (400, 100)\n",
      "Test labels: (400,)\n",
      "\n",
      "--- Label Mapping ---\n",
      "Label mapping:\n",
      "  negative -> 0\n",
      "  neutral -> 1\n",
      "  positive -> 2\n",
      "\n",
      "--- Label Distribution ---\n",
      "Class 0 (negative): Train=192 (38.40%), Val=38 (38.00% if i < len(val_label_dist) else 0.0), Test=153 (38.25% if i < len(test_label_dist) else 0.0)\n",
      "Class 1 (neutral): Train=119 (23.80%), Val=24 (24.00% if i < len(val_label_dist) else 0.0), Test=96 (24.00% if i < len(test_label_dist) else 0.0)\n",
      "Class 2 (positive): Train=189 (37.80%), Val=38 (38.00% if i < len(val_label_dist) else 0.0), Test=151 (37.75% if i < len(test_label_dist) else 0.0)\n",
      "\n",
      "--- Vocabulary Information ---\n",
      "Vocabulary size: 2836\n",
      "Top 20 vocabulary items:\n",
      "  0: \n",
      "  1: [UNK]\n",
      "  2: yang\n",
      "  3: di\n",
      "  4: dan\n",
      "  5: tidak\n",
      "  6: saya\n",
      "  7: dengan\n",
      "  8: enak\n",
      "  9: ini\n",
      "  10: makan\n",
      "  11: untuk\n",
      "  12: ke\n",
      "  13: tempat\n",
      "  14: makanan\n",
      "  15: juga\n",
      "  16: sangat\n",
      "  17: ada\n",
      "  18: banyak\n",
      "  19: karena\n",
      "\n",
      "--- Sample Data ---\n",
      "\n",
      "Sample 1:\n",
      "Label: 1 (neutral)\n",
      "Sequence length: 16\n",
      "Tokens: [1758 1080 1145  196 2834  198   11  607  177  847] ...\n",
      "First few tokens decoded:\n",
      "  1758: nikmati\n",
      "  1080: cicilan\n",
      "  1145: 0\n",
      "  196: hingga\n",
      "  2834: 12\n",
      "  198: bulan\n",
      "  11: untuk\n",
      "  607: pemesanan\n",
      "  177: tiket\n",
      "  847: pesawat\n",
      "\n",
      "Sample 2:\n",
      "Label: 2 (positive)\n",
      "Sequence length: 22\n",
      "Tokens: [2042    2  126  139    6 2625  456 1224  493  221] ...\n",
      "First few tokens decoded:\n",
      "  2042: kuekue\n",
      "  2: yang\n",
      "  126: disajikan\n",
      "  139: bikin\n",
      "  6: saya\n",
      "  2625: bernostalgia\n",
      "  456: semuanya\n",
      "  1224: tipikal\n",
      "  493: kue\n",
      "  221: zaman\n",
      "\n",
      "Sample 3:\n",
      "Label: 1 (neutral)\n",
      "Sequence length: 6\n",
      "Tokens: [ 404  155  541    3 1020  109] \n",
      "First few tokens decoded:\n",
      "  404: ibu\n",
      "  155: pernah\n",
      "  541: bekerja\n",
      "  3: di\n",
      "  1020: grab\n",
      "  109: indonesia\n",
      "\n",
      "Sample 4:\n",
      "Label: 2 (positive)\n",
      "Sequence length: 57\n",
      "Tokens: [141  76  30  10 123   3  20  57  45 376] ...\n",
      "First few tokens decoded:\n",
      "  141: paling\n",
      "  76: suka\n",
      "  30: banget\n",
      "  10: makan\n",
      "  123: siang\n",
      "  3: di\n",
      "  20: sini\n",
      "  57: ayam\n",
      "  45: sama\n",
      "  376: sambalnya\n",
      "\n",
      "Sample 5:\n",
      "Label: 2 (positive)\n",
      "Sequence length: 5\n",
      "Tokens: [  66 2559 2500   16   75] \n",
      "First few tokens decoded:\n",
      "  66: pelayanan\n",
      "  2559: bus\n",
      "  2500: damri\n",
      "  16: sangat\n",
      "  75: baik\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../indonesian'\n",
    "\n",
    "data_processor = NusaXSentimentDataProcessor(data_dir)\n",
    "print(\"Preparing data...\")\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = data_processor.prepare_data()\n",
    "\n",
    "analyze_data(x_train, y_train, x_val, y_val, x_test, y_test, data_processor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
