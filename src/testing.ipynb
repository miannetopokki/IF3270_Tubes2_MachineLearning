{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf8a04c",
   "metadata": {},
   "source": [
    "### Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "98dae489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from data_preprocessing import NusaXSentimentDataProcessor\n",
    "from LSTM.lstm import LSTMModel\n",
    "from RNN.rnn import RNNModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5be810",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7f74c329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Unique labels found: {'positive', 'negative', 'neutral'}\n",
      "Train data: 500 samples\n",
      "Validation data: 100 samples\n",
      "Test data: 400 samples\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../indonesian'\n",
    "data_processor = NusaXSentimentDataProcessor(data_dir,sequence_length = 30)# 30 timesteps\n",
    "print(\"Preparing data...\")\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = data_processor.prepare_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6410355",
   "metadata": {},
   "source": [
    "### Making Keras Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0215c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_and_train_model(x_train, \n",
    "                           y_train, \n",
    "                           x_val, \n",
    "                           y_val, \n",
    "                           vocab_size, \n",
    "                           num_classes, \n",
    "                           model_type='lstm',\n",
    "                           embedding_dim = 100, \n",
    "                           hidden_units=25,\n",
    "                           epoch=25,\n",
    "                           batch_size=32):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, embedding_dim))\n",
    "\n",
    "    # Pilih jenis RNN\n",
    "    if model_type.lower() == 'lstm':\n",
    "        model.add(keras.layers.LSTM(hidden_units))\n",
    "    elif model_type.lower() == 'simplernn':\n",
    "        model.add(keras.layers.SimpleRNN(hidden_units))\n",
    "    else:\n",
    "        raise ValueError(\"model_type harus salah satu dari: 'lstm', 'simplernn\")\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining {model_type.upper()} model with {num_classes} classes...\")\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=epoch,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def preprocess_text_for_prediction(processor: NusaXSentimentDataProcessor, text: str):\n",
    "    if processor.vectorize_layer is None:\n",
    "        raise ValueError(\"Vectorize layer belum diadaptasi. Jalankan prepare_data() dulu.\")\n",
    "\n",
    "    vectorized = processor.vectorize_text(tf.constant([text]))\n",
    "    return vectorized.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "739897af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 2836 Num Classes 3\n",
      "2836\n"
     ]
    }
   ],
   "source": [
    "vocab_size = data_processor.get_vocabulary_size()\n",
    "num_classes = data_processor.get_num_classes()\n",
    "print(f\"Vocab Size: {vocab_size} Num Classes {num_classes}\")\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4933d8",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f9a725cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model with 3 classes...\n",
      "Epoch 1/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.4084 - loss: 1.0861 - val_accuracy: 0.5000 - val_loss: 1.0607\n",
      "Epoch 2/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5262 - loss: 1.0392 - val_accuracy: 0.5000 - val_loss: 1.0125\n",
      "Epoch 3/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5448 - loss: 0.9390 - val_accuracy: 0.5300 - val_loss: 0.9343\n",
      "Epoch 4/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6576 - loss: 0.7809 - val_accuracy: 0.6100 - val_loss: 0.8646\n",
      "Epoch 5/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8194 - loss: 0.5743 - val_accuracy: 0.6400 - val_loss: 0.8082\n",
      "Epoch 6/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9660 - loss: 0.2607 - val_accuracy: 0.6100 - val_loss: 1.0540\n",
      "Epoch 7/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.1752 - val_accuracy: 0.6200 - val_loss: 1.1963\n",
      "Epoch 8/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.1477 - val_accuracy: 0.6200 - val_loss: 1.2936\n",
      "Epoch 9/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9741 - loss: 0.1316 - val_accuracy: 0.6600 - val_loss: 1.2452\n",
      "Epoch 10/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0537 - val_accuracy: 0.6500 - val_loss: 1.3493\n",
      "Epoch 11/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9957 - loss: 0.0504 - val_accuracy: 0.6200 - val_loss: 1.4450\n",
      "Epoch 12/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0839 - val_accuracy: 0.6600 - val_loss: 1.4386\n",
      "Epoch 13/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0625 - val_accuracy: 0.6500 - val_loss: 1.5121\n",
      "Epoch 14/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0548 - val_accuracy: 0.6700 - val_loss: 1.5240\n",
      "Epoch 15/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0329 - val_accuracy: 0.6400 - val_loss: 1.5681\n",
      "Epoch 16/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0203 - val_accuracy: 0.6500 - val_loss: 1.5941\n",
      "Epoch 17/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0200 - val_accuracy: 0.6600 - val_loss: 1.6197\n",
      "Epoch 18/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.6700 - val_loss: 1.6213\n",
      "Epoch 19/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.6500 - val_loss: 1.6699\n",
      "Epoch 20/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.6500 - val_loss: 1.7183\n",
      "Epoch 21/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.6500 - val_loss: 1.7649\n",
      "Epoch 22/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.6500 - val_loss: 1.8066\n",
      "Epoch 23/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6400 - val_loss: 1.8461\n",
      "Epoch 24/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6400 - val_loss: 1.8828\n",
      "Epoch 25/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6400 - val_loss: 1.9155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">283,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_31 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m283,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │        \u001b[38;5;34m12,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m78\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">888,836</span> (3.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m888,836\u001b[0m (3.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">296,278</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m296,278\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">592,558</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m592,558\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lstm,hist = create_and_train_model(x_train,y_train,x_val,y_val,vocab_size,num_classes,'lstm',epoch=25)\n",
    "model_lstm.summary()\n",
    "#rumus param lstm: (1+10+1)*4*4 = 480\n",
    "#rumus dense output: (10+1) * 3 = 33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "247ed1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture Information:\n",
      "==============================\n",
      "\n",
      "Layer 0: Embedding\n",
      "------------------------\n",
      "E (Embedding Matrix):\n",
      "  Shape: (2836, 100)\n",
      "  - rows: vocabulary size (|V|)\n",
      "  - cols: embedding dimension (d)\n",
      "\n",
      "Config:\n",
      "{'name': 'embedding_31', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'input_dim': 2836, 'output_dim': 100, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'seed': None, 'minval': -0.05, 'maxval': 0.05}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}\n",
      "\n",
      "Layer 1: LSTM\n",
      "------------------------\n",
      "Weight Matrices:\n",
      "W (Input Weight Matrix):\n",
      "  Shape: (100, 100)\n",
      "  - rows: input dimension (d)\n",
      "  - cols: 4*h where h is hidden size (for i,f,g,o gates)\n",
      "\n",
      "U (Recurrent Weight Matrix):\n",
      "  Shape: (25, 100)\n",
      "  - rows: hidden size (h)\n",
      "  - cols: 4*h (for i,f,g,o gates)\n",
      "\n",
      "b (Bias Vector):\n",
      "  Shape: (100,)\n",
      "  - size: 4*h (bias for i,f,g,o gates)\n",
      "\n",
      "LSTM Gates (each of size h=25):\n",
      "  i: Input gate      (0:25)\n",
      "  f: Forget gate     (25:50)\n",
      "  g: Cell gate       (50:75)\n",
      "  o: Output gate     (75:100)\n",
      "  c_t = f ⊙ c_{t-1} + i ⊙ g           # cell state\n",
      "  h_t = o ⊙ tanh(c_t)                  # hidden state\n",
      "\n",
      "Config:\n",
      "{'name': 'lstm_13', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 25, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'Orthogonal', 'config': {'seed': None, 'gain': 1.0}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}\n",
      "\n",
      "Layer 2: Dropout\n",
      "------------------------\n",
      "No weights in this layer\n",
      "\n",
      "Config:\n",
      "{'name': 'dropout_31', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.2, 'seed': None, 'noise_shape': None}\n",
      "\n",
      "Layer 3: Dense\n",
      "------------------------\n",
      "W (Weight Matrix):\n",
      "  Shape: (25, 3)\n",
      "  - rows: input features\n",
      "  - cols: output classes\n",
      "\n",
      "b (Bias Vector):\n",
      "  Shape: (3,)\n",
      "\n",
      "Config:\n",
      "{'name': 'dense_31', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n",
      "Formulas:\n",
      "=========\n",
      "Embedding: x = E[input_indices]\n",
      "SimpleRNN:\n",
      "  h_t = tanh(W·x + U·h_{t-1} + b)     # hidden state\n",
      "LSTM:\n",
      "  i = σ(W_i·x + U_i·h_{t-1} + b_i)    # input gate\n",
      "  f = σ(W_f·x + U_f·h_{t-1} + b_f)    # forget gate\n",
      "  g = tanh(W_g·x + U_g·h_{t-1} + b_g) # cell gate\n",
      "  o = σ(W_o·x + U_o·h_{t-1} + b_o)    # output gate\n",
      "  c_t = f ⊙ c_{t-1} + i ⊙ g           # cell state\n",
      "  h_t = o ⊙ tanh(c_t)                  # hidden state\n",
      "Dense: y = W·x + b\n"
     ]
    }
   ],
   "source": [
    "custom_model_lstm = LSTMModel(model_lstm) \n",
    "custom_model_lstm.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9804566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "y_keras = model_lstm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ef84b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total timestep: 30\n"
     ]
    }
   ],
   "source": [
    "y_scratch = custom_model_lstm.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "966cc6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total timestep: 30\n",
      "F1 Score (macro): 0.6112\n"
     ]
    }
   ],
   "source": [
    "f1_scratch, y_pred_scratch, outs = custom_model_lstm.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5bd66dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6921848  0.110659   0.19715612]]\n",
      "[[0.5978309  0.00287601 0.39929315]]\n",
      "[2 1 0 2 1 0 1 0 2 2 1 0 0 1 0 0 1 0 1 2 1 0 2 1 1 2 2 0 2 2 1 1 0 2 0 0 0\n",
      " 0 2 2 2 0 0 0 1 1 1 1 1 2 0 2 0 2 1 0 2 1 0 2 1 2 1 1 0 1 2 0 0 0 1 0 1 1\n",
      " 2 0 2 2 2 2 0 0 1 2 2 2 0 2 0 0 0 2 1 1 2 0 1 2 0 1 0 2 1 2 0 1 0 2 2 2 1\n",
      " 2 2 2 0 1 2 2 2 2 2 0 2 1 0 0 2 0 0 1 1 1 1 0 2 0 2 2 2 2 2 0 1 0 2 2 1 2\n",
      " 0 1 1 2 1 2 1 1 0 1 2 2 2 0 2 0 2 2 2 1 0 1 2 0 2 0 2 1 0 2 1 2 0 2 1 0 0\n",
      " 0 1 0 1 2 1 2 0 0 1 2 2 0 0 0 2 0 1 2 2 1 2 0 0 0 2 0 2 0 2 1 0 0 2 1 0 1\n",
      " 0 2 2 0 1 2 1 2 0 1 1 0 1 0 0 0 2 1 0 2 0 0 2 1 0 1 0 2 1 2 0 2 2 1 1 1 2\n",
      " 2 0 2 2 0 1 0 2 2 2 0 0 0 2 2 2 0 2 0 2 2 2 2 2 2 0 2 0 2 1 0 2 0 0 1 2 1\n",
      " 0 0 0 0 1 2 1 0 2 2 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 2 0 2 0 2 0 1 2 0 2 2 2\n",
      " 1 1 2 0 0 0 0 2 0 0 0 0 0 2 0 0 0 2 1 0 2 1 1 0 2 0 2 0 1 2 2 0 0 2 2 2 1\n",
      " 0 2 2 2 0 2 2 2 2 0 1 0 0 1 2 1 1 0 2 0 0 0 2 2 0 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_keras[0:1])\n",
    "print(y_scratch[0:1])\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "10997f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Keras: 0.6865293136141659\n",
      "F1 Score Scratch:  0.6112294859024047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_keras_classes = np.argmax(y_keras, axis=1)\n",
    "f1_keras = f1_score(y_test, y_keras_classes, average='macro')  \n",
    "print(\"F1 Score Keras:\", f1_keras)\n",
    "print(\"F1 Score Scratch: \", f1_scratch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c4a6ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Prediksi kalimat 'zaki sangat suka makan sayur' adalah: negative\n"
     ]
    }
   ],
   "source": [
    "input_text = \"zaki sangat suka makan sayur\"\n",
    "\n",
    "input_vector = preprocess_text_for_prediction(data_processor, input_text)\n",
    "y_pred_probs = model_lstm.predict(input_vector)\n",
    "predicted_label = y_pred_probs.argmax(axis=1)[0]\n",
    "reverse_label_mapping = {v: k for k, v in data_processor.label_mapping.items()}\n",
    "predicted_class_name = reverse_label_mapping[predicted_label]\n",
    "\n",
    "print(f\"Prediksi kalimat '{input_text}' adalah: {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73942195",
   "metadata": {},
   "source": [
    "#### SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a1335e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SIMPLERNN model with 3 classes...\n",
      "Epoch 1/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4204 - loss: 1.0800 - val_accuracy: 0.5200 - val_loss: 0.9983\n",
      "Epoch 2/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6652 - loss: 0.8088 - val_accuracy: 0.5000 - val_loss: 0.9770\n",
      "Epoch 3/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.4934 - val_accuracy: 0.5500 - val_loss: 0.9589\n",
      "Epoch 4/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.2791 - val_accuracy: 0.6000 - val_loss: 0.9762\n",
      "Epoch 5/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.1620 - val_accuracy: 0.5900 - val_loss: 1.0138\n",
      "Epoch 6/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0879 - val_accuracy: 0.5900 - val_loss: 1.0642\n",
      "Epoch 7/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0597 - val_accuracy: 0.5500 - val_loss: 1.1230\n",
      "Epoch 8/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 0.5700 - val_loss: 1.1645\n",
      "Epoch 9/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0396 - val_accuracy: 0.5600 - val_loss: 1.2198\n",
      "Epoch 10/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.5600 - val_loss: 1.2534\n",
      "Epoch 11/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.5700 - val_loss: 1.2641\n",
      "Epoch 12/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 0.5700 - val_loss: 1.2878\n",
      "Epoch 13/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.5600 - val_loss: 1.3166\n",
      "Epoch 14/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.5600 - val_loss: 1.3226\n",
      "Epoch 15/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.5700 - val_loss: 1.3690\n",
      "Epoch 16/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.5600 - val_loss: 1.4179\n",
      "Epoch 17/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.5800 - val_loss: 1.4302\n",
      "Epoch 18/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.5500 - val_loss: 1.3891\n",
      "Epoch 19/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.5500 - val_loss: 1.3663\n",
      "Epoch 20/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0111 - val_accuracy: 0.5200 - val_loss: 1.3839\n",
      "Epoch 21/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.5600 - val_loss: 1.3817\n",
      "Epoch 22/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.5700 - val_loss: 1.4059\n",
      "Epoch 23/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.5700 - val_loss: 1.4390\n",
      "Epoch 24/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.5800 - val_loss: 1.4282\n",
      "Epoch 25/25\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.5800 - val_loss: 1.4506\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">283,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_33 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m283,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m3,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m78\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">860,486</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m860,486\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286,828</span> (1.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m286,828\u001b[0m (1.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,658</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m573,658\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_rnn,hist = create_and_train_model(x_train,y_train,x_val,y_val,vocab_size,num_classes,'simplernn')\n",
    "model_rnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "47695b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture Information:\n",
      "==============================\n",
      "\n",
      "Layer 0: Embedding\n",
      "------------------------\n",
      "E (Embedding Matrix):\n",
      "  Shape: (2836, 100)\n",
      "  - rows: vocabulary size (|V|)\n",
      "  - cols: embedding dimension (d)\n",
      "\n",
      "Config:\n",
      "{'name': 'embedding_33', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'input_dim': 2836, 'output_dim': 100, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'seed': None, 'minval': -0.05, 'maxval': 0.05}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}\n",
      "\n",
      "Layer 1: SimpleRNN\n",
      "------------------------\n",
      "Weight Matrices:\n",
      "W (Input Weight Matrix):\n",
      "  Shape: (100, 25)\n",
      "  - rows: input dimension (d)\n",
      "  - cols: hidden size (h)\n",
      "\n",
      "U (Recurrent Weight Matrix):\n",
      "  Shape: (25, 25)\n",
      "  - rows: hidden size (h)\n",
      "  - cols: hidden size (h)\n",
      "\n",
      "b (Bias Vector):\n",
      "  Shape: (25,)\n",
      "  - size: hidden size (h)\n",
      "\n",
      "SimpleRNN Hidden Size: h=25\n",
      "\n",
      "Formula:\n",
      "  h_t = tanh(W·x + U·h_{t-1} + b)     # hidden state\n",
      "\n",
      "Config:\n",
      "{'name': 'simple_rnn_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 25, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'Orthogonal', 'config': {'seed': None, 'gain': 1.0}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0}\n",
      "\n",
      "Layer 2: Dropout\n",
      "------------------------\n",
      "No weights in this layer\n",
      "\n",
      "Config:\n",
      "{'name': 'dropout_33', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.2, 'seed': None, 'noise_shape': None}\n",
      "\n",
      "Layer 3: Dense\n",
      "------------------------\n",
      "W (Weight Matrix):\n",
      "  Shape: (25, 3)\n",
      "  - rows: input features\n",
      "  - cols: output classes\n",
      "\n",
      "b (Bias Vector):\n",
      "  Shape: (3,)\n",
      "\n",
      "Config:\n",
      "{'name': 'dense_33', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n",
      "Formulas:\n",
      "=========\n",
      "Embedding: x = E[input_indices]\n",
      "SimpleRNN:\n",
      "  h_t = tanh(W·x + U·h_{t-1} + b)     # hidden state\n",
      "LSTM:\n",
      "  i = σ(W_i·x + U_i·h_{t-1} + b_i)    # input gate\n",
      "  f = σ(W_f·x + U_f·h_{t-1} + b_f)    # forget gate\n",
      "  g = tanh(W_g·x + U_g·h_{t-1} + b_g) # cell gate\n",
      "  o = σ(W_o·x + U_o·h_{t-1} + b_o)    # output gate\n",
      "  c_t = f ⊙ c_{t-1} + i ⊙ g           # cell state\n",
      "  h_t = o ⊙ tanh(c_t)                  # hidden state\n",
      "Dense: y = W·x + b\n"
     ]
    }
   ],
   "source": [
    "custom_model_rnn = RNNModel(model_rnn) \n",
    "custom_model_rnn.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "17187861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n"
     ]
    }
   ],
   "source": [
    "y_keras = model_rnn.predict(x_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9b0fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tinggal predict disini\n",
    "# y_scratch = custom_model_rnn.predict(x_test[0:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
